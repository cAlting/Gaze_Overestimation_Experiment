{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "124666a6",
   "metadata": {},
   "source": [
    "# 1. Image Centering\n",
    "\n",
    "Image centering erfolgt so, dass der Mittelpunkt der Linie zwischen den Caruncula lacrimales bei y = Bildbreite/2 liegt. Die x-Position wird auf Nasenmitte festgelegt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963824a9",
   "metadata": {},
   "source": [
    "### a) Import der Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fee7fee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import der relevanten Libraries\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "import cv2\n",
    "import imageio.v2 as imageio\n",
    "from PIL import Image, ImageEnhance\n",
    "\n",
    "import mediapipe as mp\n",
    "from mlxtend.image import extract_face_landmarks\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965cbd83",
   "metadata": {},
   "source": [
    "### b) Verzeichnisse festlegen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ad80278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root: Verzeichnis mit Bildern, die ausgerichtet werden sollen\n",
    "root = r'C:\\Users\\calti\\Documents\\Masterarbeit\\Bilder'\n",
    "\n",
    "# orig_imgs: Verzeichnis mit Originalbildern (unbearbeitet)\n",
    "imgs_orig = r'C:\\Users\\calti\\Documents\\Masterarbeit\\Bilder\\JPG'\n",
    "\n",
    "# target: Verzeichnis, in dem die ausgerichteten Bilder abgespeichert werden sollen\n",
    "# (nicht benötigtes auskommentieren)\n",
    "#imgs_aligned = r'C:\\Users\\calti\\Documents\\Masterarbeit\\Bilder\\Mediapipe'\n",
    "imgs_aligned = r'C:\\Users\\calti\\Documents\\Masterarbeit\\Bilder\\mlxtend'\n",
    "\n",
    "# (opt): Verzeichnis, in dem die ausgerichteten und mit Photoshop per Content Aware Fill bearbeiteten Bilder liegen\n",
    "imgs_aligned_caf = r'C:\\Users\\calti\\Documents\\Masterarbeit\\Bilder\\Mediapipe CAF'\n",
    "\n",
    "# imgs_cropped: Verzeichnis, in das die gecroppten und resized images gespeichert werden sollen\n",
    "imgs_cropped = root+os.sep+'Cropped'\n",
    "\n",
    "# exp_dir: Verzeichnis des PsychoPy-Experimentes, in dem die Conditions-Datei mit den Bildpfaden gespeichert werden soll\n",
    "exp = r'C:\\Users\\calti\\Documents\\Masterarbeit\\PsychoPy'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b4adc7",
   "metadata": {},
   "source": [
    "### c) Helferfunktionen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbee94f",
   "metadata": {},
   "source": [
    "#### i) Image centering (Mediapipe Face Mesh 468)\n",
    "\n",
    "Code ist teilweise hier entnommen: [Stackoverflow](https://stackoverflow.com/questions/59525640/how-to-center-the-content-object-of-a-binary-image-in-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81a760fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_image(image, landmark_results, lm1 = 133, lm2 = 362, lm3 = 168, suppress_output = True):\n",
    "    \"\"\"\n",
    "    Centers an image based on the locations of specific facial landmarks detected by a landmark detection model.\n",
    "\n",
    "    Parameters:\n",
    "    image (numpy.ndarray): Input image to be centered.\n",
    "    landmark_results (mediapipe.python.solutions.face_mesh.FaceMesh): Results of landmark detection model.\n",
    "    lm1 (int, optional): Index of first landmark point to use for centering. Default is 133.\n",
    "    lm2 (int, optional): Index of second landmark point to use for centering. Default is 362.\n",
    "    lm3 (int, optional): Index of third landmark point to use for centering. Default is 168.\n",
    "    suppress_output (bool, optional): If True, suppresses output of diagnostic message printed to console. Default is True.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: Centered image.\n",
    "    float: x-coordinate of midpoint between specified landmarks in pixels.\n",
    "    float: y-coordinate of point to be centered in pixels.\n",
    "    float: angle between the line connecting the specified landmarks and the horizontal axis in degrees.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # get image width, height and center coordinates\n",
    "    height, width, chann = image.shape\n",
    "    \n",
    "    # Center of Original Input Image\n",
    "    wi=(width/2)\n",
    "    he=(height/2)\n",
    "\n",
    "    # x, y, und z Koordinaten des relevanten Punktes\n",
    "    # ipp1, ..., enthalten jeweils die x-, y- und z-Koordinaten der Landmark in normalisierter Einheit [0,1]\n",
    "    ipp1 = landmark_results.multi_face_landmarks[0].landmark[lm1] # Auge Links (Caruncula lacrimalis)\n",
    "    ipp2 = landmark_results.multi_face_landmarks[0].landmark[lm2] # Auge rechts (Caruncula lacrimalis)\n",
    "    ipp3 = landmark_results.multi_face_landmarks[0].landmark[lm3] # (Punkt etwas oberhalb der Interpupillarlinie)\n",
    "    \n",
    "    # x und y Koordinaten in Pixeln [0,1] -> Pixel\n",
    "    ipp1_x_px = ipp1.x*width\n",
    "    ipp1_y_px = ipp1.y*height\n",
    "    ipp2_x_px = ipp2.x*width\n",
    "    ipp2_y_px = ipp2.y*height\n",
    "    ipp3_y_px = ipp3.y*height\n",
    "    ipp3_x_px = ipp3.x*width\n",
    "    \n",
    "    # Bestimmung der x-Koordinate des Mittelpunktes zwischen C. lacrimalis rechts und links\n",
    "    # ipp2_x_px: x-Koordinate der C. lacrimalis rechts (landmark 362) [Pixel]\n",
    "    # ipp1_x_px: x-Koordinate der C. lacrimalis links (landmark 133)  [Pixel]\n",
    "    # ipp_half: x-Koordinate der C. lacrimalis links + die Hälfte der Distanz zwischen lm362 und lm133 [Pixel]\n",
    "    #  - dies ist die x-Koordinate des Punktes, der später bei x = Bildbreite/2 liegen soll\n",
    "    ipp_half = ipp1_x_px+(ipp2_x_px-ipp1_x_px)/2\n",
    "    \n",
    "    # Bestimmung der y-Koordinate des Punktes, der später bei y = Bildhöhe/2 liegen soll\n",
    "    if ipp1_y_px < ipp2_y_px:\n",
    "        ipp_half_2 = ipp1_y_px+(ipp2_y_px-ipp1_y_px)/2\n",
    "    else:\n",
    "        ipp_half_2 = ipp2_y_px+(ipp1_y_px-ipp2_y_px)/2\n",
    "    \n",
    "    # Bestimmung des Winkels zwischen der Linie zwischen C.l. sinister und dextra\n",
    "    dX = ipp2_x_px - ipp1_x_px\n",
    "    dY = ipp2_y_px - ipp1_y_px\n",
    "    angle = np.degrees(np.arctan2(dY, dX))\n",
    "    \n",
    "    # Offset = Differenz zwischen (x,y) des Bildzentrums und (x,y) der Landmark\n",
    "    #offsetX = (wi-ipp_half)\n",
    "    #offsetY = (he-ipp_half_2)\n",
    "    offsetX = (wi-ipp3_x_px)\n",
    "    offsetY = (he-ipp_half_2)\n",
    "    \n",
    "    if suppress_output == False:\n",
    "        msg = f'''\n",
    "        EyeL x:   {ipp1_x_px}\n",
    "        EyeR x:   {ipp2_x_px}\n",
    "        EyeL y:   {ipp1_y_px}\n",
    "        EyeR y:   {ipp2_y_px}\n",
    "        IPP x:    {ipp_half}\n",
    "        IPP y:    {ipp_half_2}\n",
    "        Offset x: {offsetX}\n",
    "        Offset y: {offsetY}\n",
    "        Angle:    {angle}\n",
    "        \\n\\n\n",
    "        '''\n",
    "        print(msg)\n",
    "    \n",
    "    # Affine matrix with Translations\n",
    "    T = np.float32([[1, 0, offsetX], [0, 1, offsetY]]) \n",
    "    \n",
    "    # WarpAffine\n",
    "    centered_image = cv2.warpAffine(image, T, (width, height))\n",
    "    \n",
    "    # Return translated Image, x-Koordinate des Punktes zwischen C.l. sinistra und dextra, Winkel\n",
    "    return centered_image, ipp_half, ipp_half_2, angle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1545b4-cebe-4b66-a90f-b549f9007dd0",
   "metadata": {},
   "source": [
    "#### ii) Image Centering (mlxtend, dlib68)\n",
    "\n",
    "Code ist teilweise hier entnommen: [Stackoverflow](https://stackoverflow.com/questions/59525640/how-to-center-the-content-object-of-a-binary-image-in-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e854c2ef-5b53-4af5-a29d-328a7daee724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_image_mlx(image, landmarks, lm1 = 39, lm2 = 42, suppress_output = True):\n",
    "\n",
    "    # get image width, height and center coordinates\n",
    "    height, width, chann = image.shape\n",
    "    \n",
    "    # Center of Original Input Image\n",
    "    wi=(width/2)\n",
    "    he=(height/2)\n",
    "\n",
    "    # x, y, und z Koordinaten des relevanten Punktes\n",
    "    # ipp1, ..., enthalten jeweils die x-, y- und z-Koordinaten der Landmark in normalisierter Einheit [0,1]\n",
    "    lm1_x = landmarks[lm1][0]\n",
    "    lm1_y = landmarks[lm1][1]\n",
    "    \n",
    "    lm2_x = landmarks[lm2][0]\n",
    "    lm2_y = landmarks[lm2][1]\n",
    "    \n",
    "    # Bestimmung der x-Koordinate des Mittelpunktes zwischen C. lacrimalis rechts und links\n",
    "    # ipp2_x_px: x-Koordinate der C. lacrimalis rechts (landmark 362) [Pixel]\n",
    "    # ipp1_x_px: x-Koordinate der C. lacrimalis links (landmark 133)  [Pixel]\n",
    "    # ipp_half: x-Koordinate der C. lacrimalis links + die Hälfte der Distanz zwischen lm362 und lm133 [Pixel]\n",
    "    #  - dies ist die x-Koordinate des Punktes, der später bei x = Bildbreite/2 liegen soll\n",
    "    ipp_half = lm1_x+(lm2_x-lm1_x)/2\n",
    "    \n",
    "    # Bestimmung der y-Koordinate des Punktes, der später bei y = Bildhöhe/2 liegen soll\n",
    "    if lm1_y < lm2_y:\n",
    "        ipp_half_2 = lm1_y+(lm2_y-lm1_y)/2\n",
    "    else:\n",
    "        ipp_half_2 = lm2_y+(lm1_y-lm2_y)/2\n",
    "    \n",
    "    # Bestimmung des Winkels zwischen der Linie zwischen C.l. sinister und dextra\n",
    "    dX = lm2_x - lm1_x\n",
    "    dY = lm2_y - lm2_y\n",
    "    angle = np.degrees(np.arctan2(dY, dX))\n",
    "    \n",
    "    # Offset = Differenz zwischen (x,y) des Bildzentrums und (x,y) der Landmark\n",
    "    #offsetX = (wi-ipp_half)\n",
    "    #offsetY = (he-ipp_half_2)\n",
    "    offsetX = (wi-ipp_half)\n",
    "    offsetY = (he-ipp_half_2)\n",
    "    \n",
    "    if suppress_output == False:\n",
    "        msg = f'''\n",
    "        EyeL x:   {lm1_x}\n",
    "        EyeR x:   {lm2_x}\n",
    "        EyeL y:   {lm1_y}\n",
    "        EyeR y:   {lm2_y}\n",
    "        IPP x:    {ipp_half}\n",
    "        IPP y:    {ipp_half_2}\n",
    "        Offset x: {offsetX}\n",
    "        Offset y: {offsetY}\n",
    "        Angle:    {angle}\n",
    "        \\n\\n\n",
    "        '''\n",
    "        print(msg)\n",
    "    \n",
    "    # Affine matrix with Translations\n",
    "    T = np.float32([[1, 0, offsetX], [0, 1, offsetY]]) \n",
    "    \n",
    "    # WarpAffine\n",
    "    centered_image = cv2.warpAffine(image, T, (width, height))\n",
    "    \n",
    "    # Return translated Image, x-Koordinate des Punktes zwischen C.l. sinistra und dextra, Winkel\n",
    "    return centered_image, ipp_half, ipp_half_2, angle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47569797",
   "metadata": {},
   "source": [
    "#### iii) Bild zu Video Konvertierung\n",
    "\n",
    "Code kommt in Teilen von diesen Seiten:  \n",
    "[TheAILearner: openCV Img to Video](https://theailearner.com/2018/10/15/creating-video-from-images-using-opencv-python/)  \n",
    "[TheAILearner: Image Resizing, wenn Input und Video Size unterschiedlich](https://theailearner.com/2018/11/15/changing-video-resolution-using-opencv-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acbdff5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_video(image_path_list: list, target_folder: str, output_name: str, size:tuple, fps=20,):\n",
    "    \"\"\"\n",
    "    Converts a list of images to a video and saves it to the specified target folder with the given output name and file format.\n",
    "\n",
    "    Args:\n",
    "    image_path_list (list): A list of file paths of the images to be included in the video.\n",
    "    target_folder (str): The path to the directory where the video file will be saved.\n",
    "    output_name (str): The name of the video file to be saved.\n",
    "    size (tuple): A tuple of width and height values representing the size of the output video.\n",
    "    fps (int, optional): The frame rate of the output video. Default is 20 frames per second.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    img_array = []\n",
    "    \n",
    "    for i, filename in enumerate(image_path_list):\n",
    "        if i%20 == 0:\n",
    "            print(f'Read Iteration: {i}')\n",
    "        \n",
    "        # Read Image\n",
    "        img = cv2.imread(filename)\n",
    "\n",
    "        # Resize Image\n",
    "        img_resized = cv2.resize(img, \n",
    "                                 size, \n",
    "                                 fx=0,\n",
    "                                 fy=0, \n",
    "                                 interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "        # Append image to list \n",
    "        img_array.append(img_resized)\n",
    "\n",
    "    # Open video writer\n",
    "    out = cv2.VideoWriter(target_folder+os.sep+output_name+'.mp4',\n",
    "                              cv2.VideoWriter_fourcc(*'mp4v'), \n",
    "                              fps, \n",
    "                              size)\n",
    "\n",
    "    # write images\n",
    "    for i in range(len(img_array)):\n",
    "        out.write(img_array[i])\n",
    "\n",
    "        if i%20 == 0:\n",
    "            print(f'Write Iteration: {i}')\n",
    "    \n",
    "    # release video writer            \n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be007283",
   "metadata": {},
   "source": [
    "#### iv) Cropping und Resizing\n",
    "\n",
    "Code ist z.T. entnommen aus der von [Gernot Horstmann](https://www.uni-bielefeld.de/fakultaeten/psychologie/abteilung/arbeitseinheiten/01/people/scientificstaff/horstmann/) zur Verfügung gestellten Datei `cutting.py`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92747ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_resize(input_folder: str, output_folder: str, output_width: int, output_height: int):\n",
    "    \"\"\"\n",
    "    Crop and resize images from a source folder and save them in a target folder.\n",
    "\n",
    "    Args:\n",
    "        input_folder (str): The path to the folder containing the source images.\n",
    "        output_folder (str): The path to the folder where the cropped and resized images will be saved.\n",
    "        output_width (int): The desired width of the output images, in pixels.\n",
    "        output_height (int): The desired height of the output images, in pixels.\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "\n",
    "    Raises:\n",
    "        OSError: If the output folder cannot be created.\n",
    "\n",
    "    The function crops and resizes images from the input folder, using a fixed aspect ratio and centering the\n",
    "    cropping around the image center. The resulting images are saved in the output folder as JPEG files, with\n",
    "    the same base name as the source files.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    print(f'Lese Bilder aus dem Verzeichnis: {input_folder}.')\n",
    "    print(f'Speichere cropped images in: {output_folder}.')\n",
    "    \n",
    "    # Check, ob Output-Folder existiert (falls nicht, wird Folder erstellt)\n",
    "    if not os.path.exists(imgs_cropped):\n",
    "        os.makedirs(imgs_cropped)\n",
    "\n",
    "    # get a list of all file names in the image directory\n",
    "    myImgList = os.listdir(input_folder)\n",
    "    myImgListEncode = [x.encode('utf-8') for x in myImgList]\n",
    "\n",
    "    # Iterieren über jedes Bild im Ordner img_aligned_caf\n",
    "    for index, thisImg in enumerate(myImgList):\n",
    "\n",
    "        # Öffnen des Bildes\n",
    "        img =Image.open(os.path.join(input_folder, thisImg))\n",
    "\n",
    "        # Optional: Image Enhancer (z.B. Helligkeit anpassen)\n",
    "        #enhancer=ImageEnhance.Brightness(img)\n",
    "        #img = enhancer.enhance(1.5)\n",
    "\n",
    "        # Bildmitte des Input Images\n",
    "        cenX = img.width//2\n",
    "        cenY = img.height//2\n",
    "\n",
    "        # Scaling Factor\n",
    "        f=50\n",
    "\n",
    "        # Cropping des Bildes\n",
    "        cropped = img.crop((\n",
    "                cenX-(100*f),\n",
    "                cenY-(100*.682*f),\n",
    "                cenX+(100*f),\n",
    "                cenY+(100*.682*f)\n",
    "                ))\n",
    "\n",
    "        # Resizing\n",
    "        x_factor = y_factor = 0.45\n",
    "        img=cropped.resize( (int(img.size[0]*x_factor), int(img.size[1]*y_factor)), Image.ANTIALIAS)\n",
    "\n",
    "        # Zentrum des cropped images\n",
    "        cenX = img.width//2\n",
    "        cenY = img.height//2\n",
    "\n",
    "        # Cropping des Bildes\n",
    "        cropped = img.crop((\n",
    "                cenX-(output_width/2),\n",
    "                cenY-(output_height/2),\n",
    "                cenX+(output_width/2),\n",
    "                cenY+(output_height/2)\n",
    "                ))\n",
    "\n",
    "        # Erstellen des Dateinamens\n",
    "        imgName = os.path.splitext(thisImg)[0]\n",
    "        outName = imgName+\".jpg\"\n",
    "        outFile = os.path.join(output_folder, outName)\n",
    "\n",
    "        # Speichern des Bildes\n",
    "        cropped.save(outFile)\n",
    "\n",
    "        if index%20 == 0:\n",
    "            print(f'Itereation {index} done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ac5d5e",
   "metadata": {},
   "source": [
    "### d) Eigentliches Centering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29aa0fe7-cc56-4831-a6eb-5d2f4a1db356",
   "metadata": {},
   "source": [
    "#### i) Mediapipe Library (468 landmarks)\n",
    "\n",
    "__Googles MediaPipe__: [Github](https://github.com/google/mediapipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf14c36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mp_drawing = mp.solutions.drawing_utils\n",
    "#mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "# Checken, ob Output-Folder existiert\n",
    "if os.path.exists(imgs_aligned) == False:\n",
    "    os.mkdir(imgs_aligned)\n",
    "\n",
    "# Liste mit absoluten Pfaden zu Originalbildern\n",
    "IMAGE_FILES = glob.glob(imgs_orig+'\\\\*JPG')\n",
    "\n",
    "print(f'''There are {len(IMAGE_FILES)} images in folder {imgs_orig}.\\n\n",
    "Target folder set to: {imgs_aligned}''')\n",
    "\n",
    "# Liste für Winkel zwischen Caruncula lacrimalis sinistra und dextra\n",
    "angles = []\n",
    "\n",
    "# Liste für Bildnamen (ohne Dateiendung). Diese wird fürs Mergen des Datensatzes mit Winkeln und Experimentaldatensatz verwendet\n",
    "names = []\n",
    "\n",
    "# Liste für Pfade zu Bilden, in denen keine Landmarks gefunden wurden\n",
    "landmarks_not_found = []\n",
    "\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "\n",
    "\n",
    "with mp_face_mesh.FaceMesh(\n",
    "    static_image_mode=True, # einzelne Bilder, kein Videostream\n",
    "    max_num_faces=1, # Maximale Anzahl an Gesichtern (da nur 1 pro Bild --> 1)\n",
    "    refine_landmarks=True, # Soll das Mesh um die Augenregion herum verfeinert werden?\n",
    "    min_detection_confidence=0.5) as face_mesh:\n",
    "\n",
    "    # über Bilddateipfade und Bilder iterieren\n",
    "    for idx, file in enumerate(IMAGE_FILES):\n",
    "        \n",
    "        if idx%20 == 0:\n",
    "            print(f'Processed image {idx} of {len(IMAGE_FILES)})\n",
    "        \n",
    "        # Einlesen des aktuellen Bildes\n",
    "        image = cv2.imread(file)\n",
    "        \n",
    "        # Generate filename (preserve original Filename)\n",
    "        img_path = Path(file)\n",
    "        name_without_ext = img_path.stem\n",
    "        name_with_ext = img_path.parts[-1]\n",
    "\n",
    "        # Convert the BGR image to RGB before processing.\n",
    "        # Results enthält die 468 landmarks\n",
    "        results = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # Fahre mit nächster Iteration fort, wenn keine Landmarks gefunden wurden\n",
    "    # Speichere die Bildpfade, für die keine Landmarks gefunden wurden\n",
    "        if not results.multi_face_landmarks:\n",
    "            print(f'Keine Landmarks gefunden in: {file}')\n",
    "            landmarks_not_found.append(file)\n",
    "            continue\n",
    "        \n",
    "        # Zentering des Bildes unter Verwendung der Standardeinstellungen (lm133, lm168, lm368)\n",
    "        centered_image, _, _, angle = center_image(image, results)\n",
    "        \n",
    "        # Speichern der Winkel zwischen der Linie, die die C.l. sinistra und dextra verbindet\n",
    "        angles.append(float(angle))\n",
    "        \n",
    "        # Speichern der Namen der Bilddateien ohne Dateiendung\n",
    "        # In meinem Fall nutze ich diese Information, um die Winkel später dem Datensatz zu matchen\n",
    "        names.append(name_without_ext)\n",
    "        \n",
    "        # Speichern des Bildes\n",
    "        cv2.imwrite(imgs_aligned+os.sep+name_with_ext , centered_image)\n",
    "\n",
    "# Erstellen eines Data Frames mit Winkeln und Bildnamen\n",
    "# Export des Data Frames als csv\n",
    "df = pd.DataFrame({\"angles\":angles, \n",
    "                   \"looker\":names})\n",
    "df[\"angles\"] = round(df[\"angles\"], 3)\n",
    "df.to_csv(root+os.sep+'angles.csv', float_format=\"%.3f\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed096ed0-e440-4f93-b7d3-0cf896ddd92a",
   "metadata": {},
   "source": [
    "#### ii) mlxtend Library (68 Landmarks)\n",
    "\n",
    "__mlextend__: [GitHub](https://github.com/rasbt/mlxtend)\n",
    "\n",
    "__Codebeispiele__ für mlxtend's `extract_face_landmarks`: [Sebastian Raschkas GitHub](https://rasbt.github.io/mlxtend/user_guide/image/extract_face_landmarks/#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11230873-2c7f-44d4-9d99-cd11bf74f682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 520 images in folder C:\\Users\\calti\\Documents\\Masterarbeit\\Bilder\\JPG.\n",
      "\n",
      "Target folder set to: C:\\Users\\calti\\Documents\\Masterarbeit\\Bilder\\mlxtend\n"
     ]
    }
   ],
   "source": [
    "# Checken, ob Output-Folder existiert\n",
    "if os.path.exists(imgs_aligned) == False:\n",
    "    os.mkdir(imgs_aligned)\n",
    "\n",
    "# Liste mit allen Originalbildern\n",
    "imgs = glob.glob(imgs_orig + \"\\*.JPG\")\n",
    "\n",
    "print(f'''There are {len(imgs)} images in folder {imgs_orig}.\\n\n",
    "Target folder set to: {imgs_aligned}''')\n",
    "\n",
    "# Liste für Angle zwischen Caruncula lacrimalis sinistra und dextra\n",
    "angles = []\n",
    "\n",
    "# Liste für Looker-IDs\n",
    "lookerIDs = []\n",
    "\n",
    "# Aus jedem Bild die Landmarks extrahieren\n",
    "for file in imgs:\n",
    "    \n",
    "    # Einlesen der Bilder\n",
    "    #img = imageio.imread(file)\n",
    "    img = cv2.imread(file)\n",
    "    \n",
    "    # Extrahieren der 68 Landmarks (dlib)\n",
    "    landmarks = extract_face_landmarks(img)\n",
    "    \n",
    "    # Zentrieren des Bildes\n",
    "    centered_image, _, _, angle = center_image_mlx(img, landmarks, suppress_output=True)\n",
    "    \n",
    "    # Namen der Outputdatei und Looker-ID extrahieren\n",
    "    img_path = Path(file)\n",
    "    name_without_ext = img_path.stem # Looker ID\n",
    "    name_with_ext = img_path.parts[-1] # Filename für zentriertes Bild\n",
    "    \n",
    "    # Speichern der Winkel zwischen der Linie, die die C.l. sinistra und dextra verbindet\n",
    "    angles.append(float(angle))\n",
    "\n",
    "    # Speichern der Namen der Bilddateien ohne Dateiendung\n",
    "    # In meinem Fall nutze ich diese Information, um die Winkel später dem Datensatz zu matchen\n",
    "    lookerIDs.append(name_without_ext)\n",
    "\n",
    "    # Speichern des Bildes\n",
    "    cv2.imwrite(imgs_aligned+os.sep+name_with_ext , centered_image)\n",
    "\n",
    "    \n",
    "# Erstellen eines Data Frames mit Winkeln und Bildnamen\n",
    "# Export des Data Frames als csv\n",
    "df = pd.DataFrame({\"angles\":angles, \n",
    "                   \"looker\":names})\n",
    "df[\"angles\"] = round(df[\"angles\"], 3)\n",
    "df.to_csv(root+os.sep+'angles.csv', float_format=\"%.3f\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678f76dc",
   "metadata": {},
   "source": [
    "### e) (opt) Überprüfen der Ausrichtungen durch Erstellen von Video aus Original- und ausgerichteten Bildern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8c9446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bilder (Original)\n",
    "imgs_orig = glob.glob(imgs_orig+'\\\\*JPG')\n",
    "\n",
    "# Bilder (resized)\n",
    "imgs_aligned = glob.glob(imgs_aligned+'\\\\*jpg')\n",
    "\n",
    "# Größe (w x h) der Output-Videodatei\n",
    "size = (1920, 1080)\n",
    "\n",
    "# Create Video of Original jpg files\n",
    "img_to_video(imgs_orig,\n",
    "             root,\n",
    "            'Original_Images',\n",
    "            size)\n",
    "\n",
    "# Create Video of aligned jpg files\n",
    "img_to_video(imgs_orig,\n",
    "             root,\n",
    "            'Aligned_Images',\n",
    "            size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdaad5b",
   "metadata": {},
   "source": [
    "# 2. Image Cropping and Resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a24048a",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_resize(imgs_aligned_caf, imgs_cropped, 1280, 1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3ee04a",
   "metadata": {},
   "source": [
    "# 3. Excel-Datei mit den Dateipfaden zu den Experimentalstimuli erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf9ad7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_paths = glob.glob(exp + os.sep + \"img_train\" + os.sep + \"*.jpg\")\n",
    "exp_img_paths = glob.glob(exp + os.sep + \"img_exp\" + os.sep + \"*.jpg\")\n",
    "\n",
    "all_paths = [train_img_paths, exp_img_paths]\n",
    "\n",
    "# create training conditions file\n",
    "\n",
    "for i, l in enumerate(all_paths):\n",
    "    \n",
    "    # Listen für Looker-ID, Blickrichtung in °Sehwinkeln und relative Bildpfade\n",
    "    looker = []\n",
    "    visAng = []\n",
    "    rel_path = []\n",
    "    visAng_corr = []\n",
    "    \n",
    "    # Iterieren über Bildpfade in entsprechender Liste \"l\"\n",
    "    for paths in l:\n",
    "\n",
    "        # split paths at each os sep, unterscore and dot\n",
    "        split_parts = re.split(r'[\\\\/_.]', paths)\n",
    "\n",
    "        # add looker id to looker list\n",
    "        looker.append(split_parts[-3])\n",
    "        \n",
    "        # add visual angle to visAng list\n",
    "        va = int(split_parts[-2])\n",
    "        visAng.append(va)\n",
    "        \n",
    "        # Trainingsdaten\n",
    "        if i == 1:\n",
    "            # Korrektur des Sehwinkels\n",
    "            if va == 0:\n",
    "                visAng_corr.append(0)\n",
    "            elif va == 1:\n",
    "                visAng_corr.append(1.1)\n",
    "            elif va == 2:\n",
    "                visAng_corr.append(2.2)\n",
    "            elif va == 3:\n",
    "                visAng_corr.append(3.3)\n",
    "            elif va == 4:\n",
    "                visAng_corr.append(4.4)\n",
    "            elif va == 5:\n",
    "                visAng_corr.append(5.5)\n",
    "            elif va == 6:\n",
    "                visAng_corr.append(6.6)\n",
    "            elif va == 7:\n",
    "                visAng_corr.append(7.7)\n",
    "            elif va == 8:\n",
    "                visAng_corr.append(8.8)\n",
    "            elif va == 9:\n",
    "                visAng_corr.append(9.9)\n",
    "            elif va == 10:\n",
    "                visAng_corr.append(11.1)\n",
    "            elif va == 11:\n",
    "                visAng_corr.append(12.2)\n",
    "            elif va == 12:\n",
    "                visAng_corr.append(13.3)\n",
    "\n",
    "        # add relative path of image file to list\n",
    "        rel_path.append(os.sep.join(paths.split(os.sep)[-2:]))\n",
    "    \n",
    "    if i == 0:\n",
    "        df_train = pd.DataFrame({'img_path': train_img_paths, \n",
    "                             'img_rel_path': rel_path, \n",
    "                             'looker': looker, \n",
    "                             'visAng': visAng})\n",
    "    else:\n",
    "        df_exp = pd.DataFrame({'img_path': exp_img_paths, \n",
    "                               'img_rel_path': rel_path, \n",
    "                               'looker': looker, \n",
    "                               'visAng': visAng,\n",
    "                               'visAngCorr': visAng_corr})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5a61cbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speichern der Trainings-Conditionfile\n",
    "#df_train.to_excel(exp+os.sep+\"cond_training.xlsx\", index=False)       \n",
    "\n",
    "# Auswählen der relevanten Blickrichtungen\n",
    "visAng_exp = [0.0, 2.2, 4.4, 6.6, 8.8, 13.3]\n",
    "\n",
    "filtered_df = df_exp[df_exp.visAngCorr.isin(visAng_exp)].copy()\n",
    "\n",
    "filtered_df[\"visAng\"] = filtered_df[\"visAng\"].astype('float64')\n",
    "filtered_df[\"visAngCorr\"] = filtered_df[\"visAngCorr\"].astype('float64')\n",
    "\n",
    "filtered_df.to_excel(exp+os.sep+\"cond_exp.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Master",
   "language": "python",
   "name": "master"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
